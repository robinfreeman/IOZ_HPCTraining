{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56ade3d-dbee-43b6-b6e5-fe8100581dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# GPU Image Classification with ResNet-152\n",
    "# --------------------------------------------------------------\n",
    "# Fine-tuning a pretrained ResNet-152 model for bird species\n",
    "# classification using PyTorch and TorchVision.\n",
    "# ==============================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c07bb31-9015-487f-bb1b-f0ccbec44d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Install dependencies (if needed) ----\n",
    "!pip install -q torch torchvision tqdm matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2995a7f-6f54-446c-9dbe-5e1fbaeae6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---- Imports ----\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import resnet152, ResNet152_Weights\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7ae09-a57d-4870-a433-d14e6444cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 1. GPU Configuration\n",
    "# ==============================================================\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12198ad-968d-47db-988a-089b92347436",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://torch-cdn.mlverse.org/datasets/bird-species.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939faf14-afd0-4fbc-b6d5-adab846bdc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -d data/bird-species bird-species.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb3e84-6eea-4f97-a22b-ad7120a16272",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 2. Dataset and Transformations\n",
    "# ==============================================================\n",
    "\n",
    "train_path = \"data/bird-species/train/\"\n",
    "test_path  = \"data/bird-species/test/\"\n",
    "\n",
    "# ---- Training transformations with augmentation ----\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ---- Validation/Test transformations (no augmentation) ----\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab6030-2288-451e-aa47-942423137b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 3. Data Loading\n",
    "# ==============================================================\n",
    "\n",
    "# Load datasets\n",
    "full_train_dataset = datasets.ImageFolder(root=train_path, transform=train_transform)\n",
    "test_dataset       = datasets.ImageFolder(root=test_path,  transform=test_transform)\n",
    "\n",
    "# Split training data into train/validation (80/20 split)\n",
    "train_size = int(0.8 * len(full_train_dataset))\n",
    "val_size   = len(full_train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, persistent_workers=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False, num_workers=4, persistent_workers=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Training images: {len(train_dataset)}\")\n",
    "print(f\"Validation images: {len(val_dataset)}\")\n",
    "print(f\"Test images: {len(test_dataset)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c10e21-6fe7-493d-b07f-f11b55d357ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 4. Model Setup\n",
    "# ==============================================================\n",
    "\n",
    "# Load pretrained ResNet-152\n",
    "model = resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "\n",
    "# Replace the fully connected layer for our dataset\n",
    "num_classes = len(full_train_dataset.classes)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),  # Regularisation\n",
    "    nn.Linear(512, num_classes)\n",
    ")\n",
    "\n",
    "# Move model to GPU (if available)\n",
    "model = model.to(device)\n",
    "\n",
    "# Unfreeze last two layers for fine-tuning\n",
    "for name, param in model.named_parameters():\n",
    "    if 'layer3' in name or 'layer4' in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b9a99b-fde7-422c-b75b-7be657c6d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 5. Optimiser, Loss Function, Scheduler\n",
    "# ==============================================================\n",
    "\n",
    "criterion  = nn.CrossEntropyLoss()\n",
    "optimizer  = optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "scheduler  = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f92995-e308-4286-81c1-5bd19e692078",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 6. Training Loop\n",
    "# ==============================================================\n",
    "\n",
    "num_epochs = 100\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Outer progress bar to track epoch progress\n",
    "with tqdm(total=num_epochs, desc=\"Overall Training Progress\") as epoch_progress:\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Show inner tqdm bars only every 20 epochs\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            train_desc = f\"Epoch {epoch+1}/{num_epochs} - Training\"\n",
    "            val_desc   = \"Validation Loop\"\n",
    "            show_progress = True\n",
    "        else:\n",
    "            train_desc = \"\"\n",
    "            val_desc   = \"\"\n",
    "            show_progress = True\n",
    "\n",
    "        # ------------------------------\n",
    "        # Training phase\n",
    "        # ------------------------------\n",
    "        for images, labels in tqdm(train_loader, desc=train_desc, disable=not show_progress):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "\n",
    "        # Compute mean training loss\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # ------------------------------\n",
    "        # Validation phase\n",
    "        # ------------------------------\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=val_desc, disable=not show_progress):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item() * labels.size(0)\n",
    "\n",
    "        val_loss = running_loss / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Update epoch progress\n",
    "        epoch_progress.update(1)\n",
    "\n",
    "        # Print summary every 20 epochs\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "                  f\"Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Step learning rate scheduler\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Optional: tqdm log message\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            tqdm.write(f\"[Epoch {epoch+1}/{num_epochs}] \"\n",
    "                       f\"Train: {train_loss:.4f} | Val: {val_loss:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "training_duration = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f87d02-77c9-46f5-8085-19fab67ec5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================\n",
    "# 7. Post-Training: Plot and Save Learning Curves\n",
    "# ==============================================================\n",
    "\n",
    "# Create results folder if it doesn’t exist\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "plot_path_png = \"results/training_validation_loss.png\"\n",
    "plot_path_pdf = \"results/training_validation_loss.pdf\"\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\", linewidth=2)\n",
    "plt.plot(val_losses, label=\"Validation Loss\", linewidth=2)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Curves\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(plot_path_png, dpi=300)\n",
    "plt.savefig(plot_path_pdf)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ Saved training loss plot to:\\n  • {plot_path_png}\\n  • {plot_path_pdf}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e7710f-7ed5-433c-a3b9-c84e9bca36cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================\n",
    "# 8. GPU Benchmark Summary\n",
    "# --------------------------------------------------------------\n",
    "# Display GPU usage and performance information\n",
    "# ==============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" GPU BENCHMARK SUMMARY \")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    total_mem = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)\n",
    "    allocated_mem = torch.cuda.memory_allocated(0) / (1024 ** 3)\n",
    "    reserved_mem = torch.cuda.memory_reserved(0) / (1024 ** 3)\n",
    "\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"Total memory: {total_mem:.2f} GB\")\n",
    "    print(f\"Allocated memory: {allocated_mem:.2f} GB\")\n",
    "    print(f\"Reserved memory: {reserved_mem:.2f} GB\")\n",
    "else:\n",
    "    print(\"Running on CPU (no CUDA GPU detected).\")\n",
    "\n",
    "print(f\"\\nTraining time: {training_duration/60:.2f} minutes\")\n",
    "print(\"=\" * 60 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
